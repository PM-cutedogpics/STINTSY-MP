{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a19fc916",
   "metadata": {},
   "source": [
    "# Description of the dataset and the task\n",
    "- Data Collection\n",
    "- Implications on the types of conclusions that could be made from the data\n",
    "- Description of the variables, observations, and/or structure of the data\n",
    "- Target task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe5f78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import dask.bag as bag\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13168578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with the filepaths for training and testing\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "train_path = Path('dataset/train')\n",
    "test_path = Path('dataset/test')\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_path, \n",
    "    validation_split=0.2, \n",
    "    subset=\"training\", \n",
    "    seed=123, \n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_path,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_path, \n",
    "    seed=123, \n",
    "    image_size=(img_height, img_width))\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "print(len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d566179",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array(train_ds.class_names)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d893e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205c84fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f382a8",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcdbb1e",
   "metadata": {},
   "source": [
    "This block of code initializes file paths for the folders and images that are going to be used for the exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52c7d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = Path('dataset/train')\n",
    "train_filepaths_jpg = list(train_dir.rglob(r'**/*.jpg'))\n",
    "train_filepaths_jpeg = list(train_dir.rglob(r'**/*.jpeg'))\n",
    "train_filepaths_png = list(train_dir.rglob(r'**/*.png'))\n",
    "train_filepaths = train_filepaths_jpg + train_filepaths_jpeg + train_filepaths_png\n",
    "\n",
    "\n",
    "def proc_img(filepath):\n",
    "    \"\"\" Create a DataFrame with the filepath and the labels of the pictures\n",
    "    \"\"\"\n",
    "\n",
    "    labels = [str(filepath[i]).split(\"\\\\\")[-2] \\\n",
    "              for i in range(len(filepath))]\n",
    "\n",
    "    filepath = pd.Series(filepath, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    # Concatenate filepaths and labels\n",
    "    df = pd.concat([filepath, labels], axis=1)\n",
    "\n",
    "    # Shuffle the DataFrame and reset index\n",
    "    df = df.sample(frac=1).reset_index(drop = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = proc_img(train_filepaths)\n",
    "train_df = train_df.sort_values(\"Label\")\n",
    "labels = train_df[\"Label\"].unique()\n",
    "labels.sort()\n",
    "train_df\n",
    "train_df.loc[train_df[\"Label\"] == label]\n",
    "\n",
    "i=0\n",
    "imagePath = {}\n",
    "\n",
    "for label in labels:\n",
    "    imagePath[i] = [fn for fn in os.listdir(f'{train_dir}\\\\{label}') if fn.endswith('.jpg')]\n",
    "    temp = [fn for fn in os.listdir(f'{train_dir}\\\\{label}') if fn.endswith('.png')]\n",
    "    for j in temp:\n",
    "        imagePath[i].append(j)\n",
    "    temp = [fn for fn in os.listdir(f'{train_dir}\\\\{label}') if fn.endswith('.jpeg')]\n",
    "    for j in temp:\n",
    "        imagePath[i].append(j)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2863322",
   "metadata": {},
   "source": [
    "# Mean Image\n",
    "The following code blocks are to obtain the mean image from each fruit and vegetable by converting the image data into a matrix of values per pixel. Each image is then compared to each other to find the mean image for that fruit/vegetable. The mean image can give us some detail in what the model is looking at as it checks pixel data of each image. Knowing this gives us a rough idea of which image should be classified as what class by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714af819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Image\n",
    "# making n X m matrix\n",
    "def img2np(path, list_of_filename, size = (64, 64)):\n",
    "    # iterating through each file\n",
    "    for fn in list_of_filename:\n",
    "        fp = path + fn\n",
    "        current_image = image.load_img(fp, target_size = size, \n",
    "                                       color_mode = 'grayscale')\n",
    "        # covert image to a matrix\n",
    "        img_ts = image.img_to_array(current_image)\n",
    "        # turn that into a vector / 1D array\n",
    "        img_ts = [img_ts.ravel()]\n",
    "        try:\n",
    "            # concatenate different images\n",
    "            full_mat = np.concatenate((full_mat, img_ts))\n",
    "        except UnboundLocalError: \n",
    "            # if not assigned yet, assign one\n",
    "            full_mat = img_ts\n",
    "    return full_mat\n",
    "\n",
    "# run it on our folders\n",
    "i=0\n",
    "imageMatrix = {}\n",
    "for label in labels:\n",
    "    imageMatrix[i] = img2np(f'{train_path}\\\\{label}\\\\', imagePath[i])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9863be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean_img(full_mat, title, size = (64, 64)):\n",
    "    # calculate the average\n",
    "    mean_img = np.mean(full_mat, axis = 0)\n",
    "    # reshape it back to a matrix\n",
    "    cmap = cm.get_cmap('Spectral')\n",
    "    mean_img = mean_img.reshape(size)\n",
    "    plt.imshow(mean_img, vmin=0, vmax=255, cmap=cmap)\n",
    "    plt.title(f'Average {title}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return mean_img\n",
    "\n",
    "i=0\n",
    "means = {}\n",
    "for label in labels:\n",
    "    means[i] = find_mean_img(imageMatrix[i], label)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5464df0",
   "metadata": {},
   "source": [
    "# Distribution of Sizes\n",
    "The distribution of sizes is shown by obtaining the dimensions of the image namely its height, weight, and depth if it has depth. The height and weight are then compiled into a scatterplot for easy visualization with each fruit and vegetable having its own graph. Knowing the distribution of sizes can help us understand which size is appropriate to be used for pre-processing purposes to normalize the sizes of each image and better tune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce1412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Sizes\n",
    "classDirectories = {}\n",
    "for label in labels:\n",
    "    classDirectories[label] = 'dataset/train/' + label + '/'\n",
    "\n",
    "def get_dims(file):\n",
    "    im = Image.open(file)\n",
    "    arr = np.array(im)\n",
    "    if (len(arr.shape) == 3):\n",
    "        h,w,d = arr.shape\n",
    "    else:\n",
    "        h,w = arr.shape\n",
    "    return h,w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c8a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,d in classDirectories.items():\n",
    "    filepath = d\n",
    "    filelist = [filepath + f for f in os.listdir(filepath)]\n",
    "    dims = bag.from_sequence(filelist).map(get_dims)\n",
    "    with ProgressBar():\n",
    "        dims = dims.compute()\n",
    "        dim_df = pd.DataFrame(dims, columns=['height', 'width'])\n",
    "        sizes = dim_df.groupby(['height', 'width']).size().reset_index().rename(columns={0:'count'})\n",
    "        sizes.plot.scatter(x='width', y='height');\n",
    "        plt.title('Image Sizes (pixels) | {}'.format(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2d33ab",
   "metadata": {},
   "source": [
    "# Distribution of Labels\n",
    "By checking the directories of each label the amount of images per fruit and vegetable can be shown in a bar graph with number of images in the y-axis and label in the x-axis. Knowing the proper distrubtion of labels can help determine which image has a different count from others. It is important for each label to have the same amount of images as it may affect the training of the model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00b5a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Labels\n",
    "for label in labels:\n",
    "    number_classes[label] = len(os.listdir(f'{train_dir}\\\\{label}'))\n",
    "f, ax = plt.subplots(figsize=(33,20)) # set the size that you'd like (width, height)\n",
    "plt.bar(number_classes.keys(), number_classes.values(), width = .5)\n",
    "plt.title(\"Number of Images by Class\");\n",
    "plt.xlabel('Class Name');\n",
    "plt.ylabel('# Images');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c3179",
   "metadata": {},
   "source": [
    "# Data Pre-processing and Cleaning\n",
    "- Change into same dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea91a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes=33\n",
    "# IMG_SIZE = 244\n",
    "# resize_and_rescale = tf.keras.Sequential([\n",
    "#   tf.keras.layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
    "#   tf.keras.layers.Rescaling(1./255)\n",
    "# ])\n",
    "\n",
    "# data_augmentation = tf.keras.Sequential([\n",
    "#     tf.keras.layers.RandomFlip(\"horizontal\",\n",
    "#                       input_shape=(img_height,\n",
    "#                                   img_width,\n",
    "#                                   3)),\n",
    "#     tf.keras.layers.RandomRotation(0.1),\n",
    "#     tf.keras.layers.RandomZoom(0.1),\n",
    "# ])\n",
    "# data_augmentation = tf.keras.Sequential([\n",
    "#   tf.keras.layers.RandomFlip('horizontal'),\n",
    "#   tf.keras.layers.RandomRotation(0.2),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e36cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "# val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a06a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = prepare(train_ds, shuffle=True, augment=True)\n",
    "# val_ds = prepare(val_ds)\n",
    "# test_ds = prepare(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896516c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#     resize_and_rescale,\n",
    "#     data_augmentation,\n",
    "#     tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(128, activation='relu'),\n",
    "#     tf.keras.layers.Dense(num_classes)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d82412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1728ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs=10\n",
    "# history = model.fit(\n",
    "#   train_ds,\n",
    "#   validation_data=val_ds,\n",
    "#   epochs=epochs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64972bb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2728b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# epochs_range = range(epochs)\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "# plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(epochs_range, loss, label='Training Loss')\n",
    "# plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c771b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, acc = model.evaluate(test_ds)\n",
    "# print(\"Accuracy\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764c5b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# img = tf.keras.utils.load_img(\n",
    "#     'Image_110.jpg', target_size=(img_height, img_width)\n",
    "# )\n",
    "# img_array = tf.keras.utils.img_to_array(img)\n",
    "# img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "# predictions = model.predict(img_array)\n",
    "# score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "# print(\n",
    "#     \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "#     .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a8e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import datetime\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1175d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
    "imagenet_labels = np.array(open(labels_path).read().splitlines())\n",
    "\n",
    "mobilenet_v2 =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n",
    "\n",
    "classifier_model = mobilenet_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadeb1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "classifier = tf.keras.Sequential([\n",
    "    hub.KerasLayer(classifier_model, input_shape=IMAGE_SHAPE+(3,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c950ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
    "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e5bef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71965c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break\n",
    "\n",
    "test_ds = test_ds.shuffle(2)\n",
    "for test_image_batch, test_labels_batch in test_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c85499",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result_batch = classifier.predict(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6499231",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_names = imagenet_labels[tf.math.argmax(result_batch, axis=-1)]\n",
    "predicted_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ece33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,9))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "for n in range(30):\n",
    "    plt.subplot(6,5,n+1)\n",
    "    plt.imshow(image_batch[n])\n",
    "    plt.title(predicted_class_names[n])\n",
    "    plt.axis('off')\n",
    "_ = plt.suptitle(\"ImageNet predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3ce5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_v2 = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "\n",
    "feature_extractor_model = mobilenet_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58769507",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_layer = hub.KerasLayer(\n",
    "    feature_extractor_model,\n",
    "    input_shape=(224, 224, 3),\n",
    "    trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_batch = feature_extractor_layer(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91c9802",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  feature_extractor_layer,\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dc8217",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaea490",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d67ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(),\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['acc'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1) # Enable histogram computation for every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcccd9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    callbacks=tensorboard_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa9e427",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffa7c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print('Test accuracy :', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ebd0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_batch = model.predict(image_batch)\n",
    "predicted_id = tf.math.argmax(predicted_batch, axis=-1)\n",
    "predicted_label_batch = class_names[predicted_id]\n",
    "print(predicted_label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad274ac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,9))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "for n in range(30):\n",
    "    plt.subplot(6,5,n+1)\n",
    "    plt.imshow(image_batch[n])\n",
    "    plt.title(predicted_label_batch[n].title())\n",
    "    plt.axis('off')\n",
    "_ = plt.suptitle(\"Model predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db72f385",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = test_ds.shuffle(2)\n",
    "for test_image_batch, test_labels_batch in test_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f46db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_batch = model.predict(test_image_batch)\n",
    "predicted_id = tf.math.argmax(predicted_batch, axis=-1)\n",
    "predicted_label_batch = class_names[predicted_id]\n",
    "print(predicted_label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7214edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,9))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "for n in range(30):\n",
    "    plt.subplot(6,5,n+1)\n",
    "    plt.imshow(test_image_batch[n])\n",
    "    plt.title(predicted_label_batch[n].title())\n",
    "    plt.axis('off')\n",
    "_ = plt.suptitle(\"Model predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d27b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "\n",
    "export_path = \"saved_models/{}\".format(int(t))\n",
    "model.save(export_path)\n",
    "\n",
    "export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78db6322",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded = tf.keras.models.load_model(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_batch = model.predict(image_batch)\n",
    "reloaded_result_batch = reloaded.predict(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e27c6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(reloaded_result_batch - result_batch).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552ee6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_predicted_id = tf.math.argmax(reloaded_result_batch, axis=-1)\n",
    "reloaded_predicted_label_batch = class_names[reloaded_predicted_id]\n",
    "print(reloaded_predicted_label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85498da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,9))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "for n in range(30):\n",
    "    plt.subplot(6,5,n+1)\n",
    "    plt.imshow(image_batch[n])\n",
    "    plt.title(reloaded_predicted_label_batch[n].title())\n",
    "    plt.axis('off')\n",
    "_ = plt.suptitle(\"Model predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ec45ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the test dataset\n",
    "reloaded_result_batch = reloaded.predict(test_image_batch)\n",
    "reloaded_predicted_id = tf.math.argmax(reloaded_result_batch, axis=-1)\n",
    "reloaded_predicted_label_batch = class_names[reloaded_predicted_id]\n",
    "print(reloaded_predicted_label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d43b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,9))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "for n in range(30):\n",
    "    plt.subplot(6,5,n+1)\n",
    "    plt.imshow(test_image_batch[n])\n",
    "    plt.title(reloaded_predicted_label_batch[n].title())\n",
    "    plt.axis('off')\n",
    "_ = plt.suptitle(\"Model predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c538fb19",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6392bee",
   "metadata": {},
   "source": [
    "# Model Selection and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98efd599",
   "metadata": {},
   "source": [
    "# Insights and conclusions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
