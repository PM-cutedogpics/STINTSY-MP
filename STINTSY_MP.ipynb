{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a19fc916",
   "metadata": {},
   "source": [
    "# Description of the dataset and the task\n",
    "- Data Collection\n",
    "- Implications on the types of conclusions that could be made from the data\n",
    "- Description of the variables, observations, and/or structure of the data\n",
    "- Target task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23fdbe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13168578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset', 'train', 'apple', 'Image_1.jpg']\n",
      "['dataset', 'test', 'apple', 'Image_1.jpg']\n",
      "['dataset', 'validation', 'apple', 'Image_1.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Create a list with the filepaths for training and testing\n",
    "train_path = Path('dataset/train')\n",
    "train_imgs_jpg = list(train_path.glob(r'**/*.jpg'))\n",
    "train_imgs_jpeg = list(train_path.glob(r'**/*.jpeg'))\n",
    "train_imgs_png = list(train_path.glob(r'**/*.png'))\n",
    "train_imgs = train_imgs_jpg + train_imgs_jpeg + train_imgs_png\n",
    "\n",
    "val_path = Path('dataset/validation')\n",
    "val_imgs_jpg = list(val_path.glob(r'**/*.jpg'))\n",
    "val_imgs_jpeg = list(val_path.glob(r'**/*.jpeg'))\n",
    "val_imgs_png = list(val_path.glob(r'**/*.png'))\n",
    "val_imgs = val_imgs_jpg + val_imgs_jpeg + val_imgs_png\n",
    "\n",
    "test_path = Path('dataset/test')\n",
    "test_imgs_jpg = list(test_path.glob(r'**/*.jpg'))\n",
    "test_imgs_jpeg = list(test_path.glob(r'**/*.jpeg'))\n",
    "test_imgs_png = list(test_path.glob(r'**/*.png'))\n",
    "test_imgs = test_imgs_jpg + test_imgs_jpeg + test_imgs_png\n",
    "\n",
    "def processData(filepath):\n",
    "    # Create a DataFrame with the filepath of the image and the labels of each\n",
    "    labels = [str(filepath[i]).split(\"\\\\\")[-2] for i in range(len(filepath))]\n",
    "\n",
    "    filepath = pd.Series(filepath, name='Filepaths').astype(str)\n",
    "    labels = pd.Series(labels, name='Labels')\n",
    "\n",
    "    # Concatenate filepaths and labels\n",
    "    df = pd.concat([filepath, labels], axis=1)\n",
    "\n",
    "    # Shuffle the DataFrame\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = processData(train_imgs)\n",
    "test_df = processData(test_imgs)\n",
    "val_df = processData(val_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "205c84fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Training set -----\n",
      "Number of images: 3278\n",
      "\n",
      "Number of different labels: 36\n",
      "\n",
      "Labels: ['chilli pepper' 'lettuce' 'garlic' 'cucumber' 'potato' 'orange' 'pear'\n",
      " 'grapes' 'capsicum' 'corn' 'raddish' 'ginger' 'peas' 'banana' 'jalepeno'\n",
      " 'turnip' 'sweetpotato' 'paprika' 'cauliflower' 'carrot' 'pomegranate'\n",
      " 'watermelon' 'lemon' 'mango' 'eggplant' 'cabbage' 'sweetcorn' 'pineapple'\n",
      " 'beetroot' 'onion' 'bell pepper' 'spinach' 'apple' 'kiwi' 'tomato'\n",
      " 'soy beans']\n",
      "\n",
      "----- validation set -----\n",
      "Number of images: 340\n",
      "\n",
      "Number of different labels: 36\n",
      "\n",
      "Labels: ['bell pepper' 'capsicum' 'sweetcorn' 'spinach' 'mango' 'onion'\n",
      " 'sweetpotato' 'chilli pepper' 'jalepeno' 'watermelon' 'apple' 'cabbage'\n",
      " 'peas' 'pomegranate' 'raddish' 'corn' 'eggplant' 'carrot' 'lettuce'\n",
      " 'potato' 'banana' 'ginger' 'orange' 'pineapple' 'lemon' 'turnip' 'kiwi'\n",
      " 'garlic' 'grapes' 'cucumber' 'beetroot' 'paprika' 'tomato' 'soy beans'\n",
      " 'pear' 'cauliflower']\n",
      "\n",
      "----- Test set -----\n",
      "Number of images: 340\n",
      "\n",
      "Number of different labels: 36\n",
      "\n",
      "Labels: ['sweetpotato' 'capsicum' 'ginger' 'turnip' 'paprika' 'soy beans'\n",
      " 'bell pepper' 'spinach' 'kiwi' 'apple' 'eggplant' 'pear' 'watermelon'\n",
      " 'potato' 'sweetcorn' 'cauliflower' 'lemon' 'chilli pepper' 'grapes'\n",
      " 'onion' 'tomato' 'cucumber' 'carrot' 'beetroot' 'pineapple' 'peas'\n",
      " 'raddish' 'pomegranate' 'jalepeno' 'corn' 'cabbage' 'garlic' 'mango'\n",
      " 'orange' 'lettuce' 'banana']\n"
     ]
    }
   ],
   "source": [
    "print('----- Training set -----')\n",
    "print(f'Number of images: {train_df.shape[0]}\\n')\n",
    "print(f'Number of different labels: {len(train_df.Labels.unique())}\\n')\n",
    "print(f'Labels: {train_df.Labels.unique()}')\n",
    "\n",
    "print('\\n----- Validation set -----')\n",
    "print(f'Number of images: {val_df.shape[0]}\\n')\n",
    "print(f'Number of different labels: {len(val_df.Labels.unique())}\\n')\n",
    "print(f'Labels: {val_df.Labels.unique()}')\n",
    "\n",
    "print('\\n----- Test set -----')\n",
    "print(f'Number of images: {test_df.shape[0]}\\n')\n",
    "print(f'Number of different labels: {len(test_df.Labels.unique())}\\n')\n",
    "print(f'Labels: {test_df.Labels.unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3400ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DataFrame with the filepaths in one column and the labels in the other one\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f382a8",
   "metadata": {},
   "source": [
    "# Exploratory data analysis\n",
    "- Mean Image\n",
    "- Distribution of the Size of Images\n",
    "- Distribution of labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c3179",
   "metadata": {},
   "source": [
    "# Data Pre-processing and Cleaning\n",
    "- Change into same dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea91a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and augment the images for the CNN model\n",
    "pp_function = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "train_img_generator = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=pp_function)\n",
    "test_img_generator = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=pp_function)\n",
    "\n",
    "train_images = train_img_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=0,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "val_images = train_img_generator.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=0,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "test_images = test_img_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc46874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = tf.keras.applications.MobileNetV2(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c538fb19",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6392bee",
   "metadata": {},
   "source": [
    "# Model Selection and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98efd599",
   "metadata": {},
   "source": [
    "# Insights and conclusions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
